{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e54616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73056dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:47:32.976998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-04 14:47:33.050116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.050573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-02-04 14:47:33.050618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.051049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2022-02-04 14:47:33.051195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-02-04 14:47:33.052064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-02-04 14:47:33.052816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-02-04 14:47:33.052983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-02-04 14:47:33.054232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-02-04 14:47:33.055040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-02-04 14:47:33.057318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-04 14:47:33.057390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.057819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.058225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.058618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.059003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2022-02-04 14:47:33.059245: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-02-04 14:47:33.063114: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz\n",
      "2022-02-04 14:47:33.063422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c12a82dc70 executing computations on platform Host. Devices:\n",
      "2022-02-04 14:47:33.063434: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2022-02-04 14:47:33.222566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.222924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-02-04 14:47:33.222973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.223320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2022-02-04 14:47:33.223346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-02-04 14:47:33.223356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-02-04 14:47:33.223364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-02-04 14:47:33.223372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-02-04 14:47:33.223380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-02-04 14:47:33.223389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-02-04 14:47:33.223397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-02-04 14:47:33.223430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.223782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.224139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.224487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.224817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2022-02-04 14:47:33.224838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-02-04 14:47:33.225588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-04 14:47:33.225596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2022-02-04 14:47:33.225599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N \n",
      "2022-02-04 14:47:33.225602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N \n",
      "2022-02-04 14:47:33.225670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.226025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.226385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.226737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.227078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9608 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-02-04 14:47:33.227343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.227731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-04 14:47:33.228070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10310 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2022-02-04 14:47:33.229262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c129a6d870 executing computations on platform CUDA. Devices:\n",
      "2022-02-04 14:47:33.229273: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-02-04 14:47:33.229276: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    }
   ],
   "source": [
    "rnn_layer = tf.keras.layers.SimpleRNN(\n",
    "    units=2, use_bias=True,\n",
    "    return_sequences=True)\n",
    "\n",
    "rnn_layer.build(input_shape=(None, None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67240410",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xh, w_oo, b_h = rnn_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae78b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: (5, 2)\n",
      "W_oo shape: (2, 2)\n",
      "b_h shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "print('W_xh shape:', w_xh.shape)\n",
    "print('W_oo shape:', w_oo.shape)\n",
    "print('b_h shape:', b_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787f78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = tf.convert_to_tensor(\n",
    "    [[1.0]*5, [2.0]*5, [3.0]*5],\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99803aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 14:47:33.637239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    }
   ],
   "source": [
    "## output of SimpleRNN\n",
    "output = rnn_layer(tf.reshape(x_seq, shape=(1,3,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f916cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      "   Input             : [[1. 1. 1. 1. 1.]]\n",
      "   Hidden            : [[0.41464037 0.96012145]]\n",
      "   Output  (manual): [[0.39240566 0.744331  ]]\n",
      "   SimpleRNN output: [0.39240566 0.744331  ]\n",
      "\n",
      "Time step 1 =>\n",
      "   Input             : [[2. 2. 2. 2. 2.]]\n",
      "   Hidden            : [[0.82928073 1.9202429 ]]\n",
      "   Output  (manual): [[0.8011651 0.9912947]]\n",
      "   SimpleRNN output: [0.8011651 0.9912947]\n",
      "\n",
      "Time step 2 =>\n",
      "   Input             : [[3. 3. 3. 3. 3.]]\n",
      "   Hidden            : [[1.243921  2.8803642]]\n",
      "   Output  (manual): [[0.9546827 0.999307 ]]\n",
      "   SimpleRNN output: [0.9546827 0.999307 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## manually computing the output:\n",
    "out_man = []\n",
    "for t in range(len(x_seq)):\n",
    "    xt = tf.reshape(x_seq[t], (1,5))\n",
    "    print('Time step {} =>'.format(t))\n",
    "    print('   Input             :', xt.numpy())\n",
    "    \n",
    "    ht = tf.matmul(xt, w_xh) + b_h\n",
    "    print('   Hidden            :', ht.numpy())\n",
    "    \n",
    "    if t>0:\n",
    "        prev_o = out_man[t-1]\n",
    "    else:\n",
    "        prev_o = tf.zeros(shape=(ht.shape))\n",
    "    ot = ht + tf.matmul(prev_o, w_oo)\n",
    "    ot = tf.math.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print('   Output  (manual):', ot.numpy())\n",
    "    print('   SimpleRNN output:'.format(t),\n",
    "          output[0][t].numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b165ee00",
   "metadata": {},
   "source": [
    "# Implementing RNNs for sequence modeling in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e84dbf",
   "metadata": {},
   "source": [
    "# Project one - predicting the sentiment of IMDb movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e738e6",
   "metadata": {},
   "source": [
    "## Preparing the movie review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46cf9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81d883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160c1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: create a dataset\n",
    "target = df.pop('sentiment')\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467674e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
      "b'OK... so... I really like Kris Kristofferson and h' 0\n",
      "b'***SPOILER*** Do not read this, if you think about' 0\n"
     ]
    }
   ],
   "source": [
    "## inspection:\n",
    "for ex in ds_raw.take(3):\n",
    "    tf.print(ex[0].numpy()[0][:50], ex[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc28f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds_raw = ds_raw.shuffle(50000, reshuffle_each_iteration=False)\n",
    "\n",
    "ds_raw_test = ds_raw.take(25000)\n",
    "ds_raw_train_valid = ds_raw.skip(25000)\n",
    "ds_raw_train = ds_raw_train_valid.take(20000)\n",
    "ds_raw_valid = ds_raw_train_valid.skip(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc75f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 87007\n"
     ]
    }
   ],
   "source": [
    "## Step 2: find unique tokens (words)\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "token_counts = Counter()\n",
    "\n",
    "for example in ds_raw_train:\n",
    "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
    "    token_counts.update(tokens)\n",
    "    \n",
    "print('Vocab-size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "706d39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232, 9, 270, 1123]\n"
     ]
    }
   ],
   "source": [
    "## Step 3: encoding unique tokens to integers\n",
    "encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
    "example_str = 'This is an example!'\n",
    "print(encoder.encode(example_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf1b1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-A: define the function for transformation\n",
    "def encode(text_tensor, label):\n",
    "    text = text_tensor.numpy()[0]\n",
    "    encoded_text = encoder.encode(text)\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea2d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-B: wrap the encode function to a TF Op.\n",
    "def encode_map_fn(text, label):\n",
    "    return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "957be3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_raw_train.map(encode_map_fn)\n",
    "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
    "ds_test = ds_raw_test.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a05f61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length: (24,)\n",
      "Sequence length: (179,)\n",
      "Sequence length: (262,)\n",
      "Sequence length: (535,)\n",
      "Sequence length: (130,)\n"
     ]
    }
   ],
   "source": [
    "# look at the shape of some examples:\n",
    "tf.random.set_seed(1)\n",
    "for example in ds_train.shuffle(1000).take(5):\n",
    "    print('Sequence length:', example[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3894b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual size: (119,)\n",
      "Individual size: (688,)\n",
      "Individual size: (308,)\n",
      "Individual size: (204,)\n",
      "Individual size: (326,)\n",
      "Individual size: (240,)\n",
      "Individual size: (127,)\n",
      "Individual size: (453,)\n"
     ]
    }
   ],
   "source": [
    "## Take a small subset\n",
    "ds_subset = ds_train.take(8)\n",
    "for example in ds_subset:\n",
    "    print('Individual size:', example[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "558ff4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dividing the dataset into batches\n",
    "ds_batched = ds_subset.padded_batch(4, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96949db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch dimension: (4, 688)\n",
      "Batch dimension: (4, 453)\n"
     ]
    }
   ],
   "source": [
    "for batch in ds_batched:\n",
    "    print('Batch dimension:', batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd5cd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ds_train.padded_batch(32, padded_shapes=([-1],[]))\n",
    "valid_data = ds_valid.padded_batch(32, padded_shapes=([-1],[]))\n",
    "test_data = ds_test.padded_batch(32, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d2172c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed-layer (Embedding)      (None, 20, 6)             600       \n",
      "=================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=100,\n",
    "                    output_dim=6,\n",
    "                    input_length=20,\n",
    "                    name='embed-layer'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf1fe59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48baacfe",
   "metadata": {},
   "source": [
    "# Building an RNN model (generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "779799a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          32000     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 36,193\n",
      "Trainable params: 36,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4b858",
   "metadata": {},
   "source": [
    "# Building an RNN model for the sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a56724b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed-layer (Embedding)      (None, None, 20)          1740180   \n",
      "_________________________________________________________________\n",
      "bidir-lstm (Bidirectional)   (None, 128)               43520     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,792,021\n",
      "Trainable params: 1,792,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:14:40.483454: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_48742_49225' and '__inference___backward_cudnn_lstm_with_fallback_47914_48096_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_49948' both implement 'lstm_5bef1d5e-c323-4a67-8922-8636f5e5d183' but their signatures do not match.\n",
      "2022-02-04 15:14:40.742315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    625/Unknown - 56s 89ms/step - loss: 0.4990 - accuracy: 0.7466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:15:34.392361: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:15:34.394142: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2022-02-04 15:15:34.773855: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference_standard_lstm_112494' and '__inference_cudnn_lstm_with_fallback_112607_specialized_for_sequential_2_bidir-lstm_backward_lstm-layer_StatefulPartitionedCall_at___inference_distributed_function_112866' both implement 'lstm_9fea0ad8-a76d-4595-bd86-a911fb29f98d' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 63s 101ms/step - loss: 0.4990 - accuracy: 0.7466 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.8947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:16:33.622136: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:16:33.622507: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 59s 94ms/step - loss: 0.2715 - accuracy: 0.8946 - val_loss: 0.5304 - val_accuracy: 0.7726\n",
      "Epoch 3/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:17:32.245928: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:17:32.247990: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 59s 94ms/step - loss: 0.1568 - accuracy: 0.9448 - val_loss: 0.4622 - val_accuracy: 0.8234\n",
      "Epoch 4/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:18:31.044699: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:18:31.046773: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 59s 94ms/step - loss: 0.0916 - accuracy: 0.9708 - val_loss: 0.5308 - val_accuracy: 0.8272\n",
      "Epoch 5/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:19:30.454219: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:19:30.454574: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 60s 95ms/step - loss: 0.0712 - accuracy: 0.9776 - val_loss: 0.6364 - val_accuracy: 0.8164\n",
      "Epoch 6/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:20:29.705076: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:20:29.705472: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 59s 95ms/step - loss: 0.0483 - accuracy: 0.9852 - val_loss: 0.7070 - val_accuracy: 0.8068\n",
      "Epoch 7/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:21:27.822941: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:21:27.824844: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 58s 92ms/step - loss: 0.0356 - accuracy: 0.9901 - val_loss: 0.8248 - val_accuracy: 0.8224\n",
      "Epoch 8/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:22:24.737447: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:22:24.737793: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 57s 91ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.7758 - val_accuracy: 0.8188\n",
      "Epoch 9/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:23:22.483559: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:23:22.483934: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 58s 92ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.6583 - val_accuracy: 0.7986\n",
      "Epoch 10/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 15:24:19.670655: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-04 15:24:19.673039: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 57s 91ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.8217 - val_accuracy: 0.8062\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.8354 - accuracy: 0.8066\n",
      "Test Acc.: 80.66%\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 20\n",
    "vocab_size = len(token_counts) + 2\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "## build the model\n",
    "bi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        name='embed-layer'),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, name='lstm-layer'),\n",
    "        name='bidir-lstm'),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bi_lstm_model.summary()\n",
    "\n",
    "## compile and train:\n",
    "bi_lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = bi_lstm_model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10)\n",
    "\n",
    "## evaluate on the test data\n",
    "test_results = bi_lstm_model.evaluate(test_data)\n",
    "print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131d4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def preprocess_datasets(\n",
    "    ds_raw_train,\n",
    "    ds_raw_valid,\n",
    "    ds_raw_test,\n",
    "    max_seq_length=None,\n",
    "    batch_size=32):\n",
    "    \n",
    "    ## (step 1 is already done - ABOVE!)\n",
    "    ## Step 2: find unique tokens\n",
    "    tokenizer = tfds.features.text.Tokenizer()\n",
    "    token_counts = Counter()\n",
    "    \n",
    "    for example in ds_raw_train:\n",
    "        tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
    "        if max_seq_length is not None:\n",
    "            tokens = tokens[-max_seq_length:]\n",
    "        token_counts.update(tokens)\n",
    "        \n",
    "    print('Vocab-size:', len(token_counts))\n",
    "    \n",
    "    ## Step 3: encoding the texts\n",
    "    encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
    "    \n",
    "    def encode(text_tensor, label):\n",
    "        text = text_tensor.numpy()[0]\n",
    "        encoded_text = encoder.encode(text)\n",
    "        if max_seq_length is not None:\n",
    "            encoded_text = encoded_text[-max_seq_length:]\n",
    "        return encoded_text, label\n",
    "    \n",
    "    def encode_map_fn(text, label):\n",
    "        return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
    "    \n",
    "    ds_train = ds_raw_train.map(encode_map_fn)\n",
    "    ds_valid = ds_raw_valid.map(encode_map_fn)\n",
    "    ds_test = ds_raw_test.map(encode_map_fn)\n",
    "    \n",
    "    ## Step 4: batching the datasets\n",
    "    train_data = ds_train.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "    \n",
    "    valid_data = ds_valid.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "    \n",
    "    test_data = ds_test.padded_batch(\n",
    "        batch_size, padded_shapes=([-1],[]))\n",
    "    \n",
    "    return (train_data, valid_data, test_data, len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5988ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58147aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(embedding_dim, vocab_size,\n",
    "                    recurrent_type='SimpleRNN',\n",
    "                    n_recurrent_units=64,\n",
    "                    n_recurrent_layers=1,\n",
    "                    bidirectional=True):\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    \n",
    "    # build the model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(\n",
    "        Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim,\n",
    "            name='embed-layer'))\n",
    "    \n",
    "    for i in range(n_recurrent_layers):\n",
    "        return_sequences = (i < n_recurrent_layers-1)\n",
    "        \n",
    "        if recurrent_type == 'SimpleRNN':\n",
    "            recurrent_layer = SimpleRNN(\n",
    "                units=n_recurrent_units,\n",
    "                return_sequences=return_sequences,\n",
    "                name='simprnn-layer-{}'.format(i))\n",
    "            \n",
    "        elif recurrent_type == 'LSTM':\n",
    "            recurrent_layer = LSTM(\n",
    "                units=n_recurrent_units,\n",
    "                return_sequences=return_sequences,\n",
    "                name='lstm-layer-{}'.format(i))\n",
    "            \n",
    "        elif recurrent_type == 'GRU':\n",
    "            recurrent_layer = GRU(\n",
    "                units=n_recurrent_units,\n",
    "                return_sequences=return_sequences,\n",
    "                name='gru-layer-{}'.format(i))\n",
    "            \n",
    "        if bidirectional:\n",
    "            recurrent_layer = Bidirectional(\n",
    "                recurrent_layer, name='bidir-' + recurrent_layer.name)\n",
    "            \n",
    "        model.add(recurrent_layer)\n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b31f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 58063\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed-layer (Embedding)      (None, None, 20)          1161300   \n",
      "_________________________________________________________________\n",
      "bidir-simprnn-layer-0 (Bidir (None, 128)               10880     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,180,501\n",
      "Trainable params: 1,180,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "embedding_dim = 20\n",
    "max_seq_length = 100\n",
    "\n",
    "train_data, valid_data, test_data, n = preprocess_datasets(\n",
    "    ds_raw_train, ds_raw_valid, ds_raw_test,\n",
    "    max_seq_length=max_seq_length,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "vocab_size = n + 2\n",
    "\n",
    "rnn_model = build_rnn_model(\n",
    "    embedding_dim, vocab_size,\n",
    "    recurrent_type='SimpleRNN',\n",
    "    n_recurrent_units=64,\n",
    "    n_recurrent_layers=1,\n",
    "    bidirectional=True)\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e85f4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41f3c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    625/Unknown - 36s 58ms/step - loss: 0.7002 - accuracy: 0.5056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:26:11.618106: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:26:11.618172: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 40s 65ms/step - loss: 0.7002 - accuracy: 0.5056 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6884 - accuracy: 0.5343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:26:52.143103: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:26:52.143173: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 40s 65ms/step - loss: 0.6884 - accuracy: 0.5343 - val_loss: 0.6466 - val_accuracy: 0.6356\n",
      "Epoch 3/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5541 - accuracy: 0.7190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:27:31.344497: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:27:31.344905: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 39s 63ms/step - loss: 0.5541 - accuracy: 0.7192 - val_loss: 0.6097 - val_accuracy: 0.7360\n",
      "Epoch 4/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:28:10.277307: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:28:10.277375: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 39s 63ms/step - loss: 0.4048 - accuracy: 0.8186 - val_loss: 0.5181 - val_accuracy: 0.7972\n",
      "Epoch 5/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.8742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:28:49.296250: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:28:49.296311: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 39s 62ms/step - loss: 0.3186 - accuracy: 0.8741 - val_loss: 0.6068 - val_accuracy: 0.7242\n",
      "Epoch 6/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.8536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:29:28.867367: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:29:28.867436: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 40s 63ms/step - loss: 0.3357 - accuracy: 0.8536 - val_loss: 0.5416 - val_accuracy: 0.7876\n",
      "Epoch 7/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:30:18.442901: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:30:18.442968: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 50s 79ms/step - loss: 0.2142 - accuracy: 0.9253 - val_loss: 0.5697 - val_accuracy: 0.7908\n",
      "Epoch 8/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:30:57.708266: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:30:57.708330: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 39s 63ms/step - loss: 0.1632 - accuracy: 0.9474 - val_loss: 0.5847 - val_accuracy: 0.7976\n",
      "Epoch 9/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.8273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:31:36.665933: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:31:36.666013: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 39s 63ms/step - loss: 0.3603 - accuracy: 0.8268 - val_loss: 0.6621 - val_accuracy: 0.5776\n",
      "Epoch 10/10\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4247 - accuracy: 0.7978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-04 16:32:15.722919: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2022-02-04 16:32:15.722984: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.4247 - accuracy: 0.7980 - val_loss: 0.5661 - val_accuracy: 0.7788\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69247e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 22s 28ms/step - loss: 0.5561 - accuracy: 0.7791\n",
      "Test Acc.: 77.91%\n"
     ]
    }
   ],
   "source": [
    "results = rnn_model.evaluate(test_data)\n",
    "print('Test Acc.: {:.2f}%'.format(results[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3beea3",
   "metadata": {},
   "source": [
    "# Project two - character-level language modeling in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3bb3260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading and processing text\n",
    "with open('1268-0.txt','r') as fp:\n",
    "    text=fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b0e89eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c763f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1112350,)\n",
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape:', text_encoded.shape)\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(text_encoded[15:21], '== Reverse ==>', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebc0c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4f58b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1051cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function for splitting x & y\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f5e7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c89396ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      " Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      " Target (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print(' Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19f6f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15eabc",
   "metadata": {},
   "source": [
    "# Building a character-level RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ddddbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(\n",
    "            rnn_units,\n",
    "            return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef088961",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the training parameters\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01cf8b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model = build_model(\n",
    "    vocab_size=charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ceda5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3eb37272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:40:52.766119: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_1838678_1838860' and '__inference___backward_cudnn_lstm_with_fallback_1838678_1838860_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_1839647' both implement 'lstm_f865130b-54ba-4a2a-927e-94bc3adb2a45' but their signatures do not match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 11s 26ms/step - loss: 2.3236\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:02.946502: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2022-02-05 11:41:02.946656: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.7509\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:12.311161: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2022-02-05 11:41:12.311236: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 23ms/step - loss: 1.5498\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:21.931604: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[sequential_4/embedding_1/embedding_lookup/_20]]\n",
      "2022-02-05 11:41:21.931676: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.4349\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:31.070938: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[loss/dense_5_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_4/_48]]\n",
      "2022-02-05 11:41:31.071091: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 23ms/step - loss: 1.3615\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:40.823690: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2022-02-05 11:41:40.823816: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.3099\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:50.080363: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[loss/dense_5_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_2/_46]]\n",
      "2022-02-05 11:41:50.080445: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.2712\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:41:59.256066: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-05 11:41:59.256164: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 22ms/step - loss: 1.2403\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:08.753994: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[sequential_4/embedding_1/embedding_lookup/_20]]\n",
      "2022-02-05 11:42:08.754159: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 21ms/step - loss: 1.2154\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:17.683140: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Adam/Adam/update/AssignSubVariableOp/_59]]\n",
      "2022-02-05 11:42:17.683160: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.1924\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:27.112344: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2022-02-05 11:42:27.112530: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 24ms/step - loss: 1.1737\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:37.137860: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[sequential_4/embedding_1/embedding_lookup/_20]]\n",
      "2022-02-05 11:42:37.137944: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 23ms/step - loss: 1.1567\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:46.953850: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[sequential_4/embedding_1/embedding_lookup/_20]]\n",
      "2022-02-05 11:42:46.953859: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 24ms/step - loss: 1.1402\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:42:56.963893: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2022-02-05 11:42:56.963910: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 23ms/step - loss: 1.1252\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:06.734654: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[sequential_4/embedding_1/embedding_lookup/_20]]\n",
      "2022-02-05 11:43:06.734797: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 24ms/step - loss: 1.1110\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:16.705643: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Shape/_6]]\n",
      "2022-02-05 11:43:16.705694: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 23ms/step - loss: 1.0974\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:26.360025: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Adam/Adam/update/AssignSubVariableOp/_59]]\n",
      "2022-02-05 11:43:26.360074: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 24ms/step - loss: 1.0842\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:36.478169: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[VariableShape/_22]]\n",
      "2022-02-05 11:43:36.478239: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 10s 24ms/step - loss: 1.0718\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:46.451316: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[loss/dense_5_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert/data_1/_44]]\n",
      "2022-02-05 11:43:46.451408: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 22ms/step - loss: 1.0593\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:43:55.909523: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2022-02-05 11:43:55.909696: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 9s 21ms/step - loss: 1.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 11:44:04.907992: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2022-02-05 11:44:04.908195: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1e10ea090>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a033cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "array([[1, 2, 0, 1, 0, 1, 1, 2, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fe8c3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:  [0.10650698 0.10650698 0.78698605]\n",
      "array([[2, 2, 0, 2, 2, 2, 2, 2, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21a1e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str,\n",
    "           len_generated_text=500,\n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1,-1))\n",
    "    \n",
    "    generated_str = starting_str\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "        \n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
    "        \n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "        \n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat(\n",
    "            [encoded_input, new_char_indx], axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "        \n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a366089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was explored that the first plan was loaded. Coffer strange\n",
      "men.\n",
      "\n",
      "The product was to drow the palicans. To enormous\n",
      "coast to make their foot of the palisade.\n",
      "He kept the Bonadventure was prolonged\n",
      "up, listened.\n",
      "\n",
      "An\n",
      "horror he speak in this basaltic rocks which ought be\n",
      "so, added the reporter, it ane cetallited with the mountain.\n",
      "\n",
      "As to Herbert?\n",
      "\n",
      "No, no marine intervention of Lincoln Island!\n",
      "\n",
      "The lay our quite question, exclaimed; Certainly, I will try boy some was evidently\n",
      "nothing to g\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cada2e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:        [0.10650698 0.10650698 0.78698604]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611688]\n",
      "Probabilities after scaling with 0.1: [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:       ',\n",
    "      tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:',\n",
    "      tf.math.softmax(0.5*logits).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:',\n",
    "      tf.math.softmax(0.1*logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2bdfe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was in the lantern, which would have been seen from the new men crew with the colonists were able to redoun to establish it again. What would be the presence of the plateau of the ore, or carrying the world, threw them to the corral when the sea before the gloom, and besides the water which he was able to distress to their news\n",
      "than the last fellow-creatures, and the\n",
      "reporter than the mountain, and the place where the colonists were from the cart, which were prolonged entirely from\n",
      "the sea and \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b06aaa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island was egblopy hould going\n",
      "at\n",
      "LoHo pounds, that\n",
      "if Cup than\n",
      "in the\n",
      "rejo.\n",
      "-At of\n",
      "anctobl.\n",
      "Ha puned; certs of ebopest,\n",
      "copphirat; unfercent grey,\n",
      "sin hear, evaxisyened; Prospear 1652 of Migila!\n",
      "\n",
      "We can, at lew tro.\n",
      "He-\n",
      "When you, skilfloud delbay rock to espegit goods bount,! Then,\n",
      "forcent, Sich in senel! they reling likely obscute\n",
      "of feel?)?s, smenizon wanderfar at fare.\n",
      "\n",
      "Yeb Nebs relun. He had calked;\n",
      "years,\n",
      "give, yem if any extremity veucg, lands shoked, with the rooms, always sombling Apue \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36f5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
